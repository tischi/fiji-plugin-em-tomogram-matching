package de.embl.cba.em.bdv;

import bdv.export.*;
import bdv.ij.export.imgloader.ImagePlusImgLoader;
import bdv.ij.util.PluginHelper;
import bdv.img.hdf5.Hdf5ImageLoader;
import bdv.img.hdf5.Partition;
import bdv.spimdata.SequenceDescriptionMinimal;
import bdv.spimdata.SpimDataMinimal;
import bdv.spimdata.XmlIoSpimDataMinimal;
import ij.IJ;
import ij.ImagePlus;
import mpicbg.spim.data.generic.sequence.BasicViewSetup;
import mpicbg.spim.data.registration.ViewRegistration;
import mpicbg.spim.data.registration.ViewRegistrations;
import mpicbg.spim.data.sequence.Channel;
import mpicbg.spim.data.sequence.FinalVoxelDimensions;
import mpicbg.spim.data.sequence.TimePoint;
import mpicbg.spim.data.sequence.TimePoints;
import net.imglib2.FinalDimensions;
import net.imglib2.RandomAccessibleInterval;
import net.imglib2.realtransform.AffineTransform3D;

import java.io.File;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Map;

public class BdvExport
{

	public static void export( ImagePlus imp,
						String filePath,
						double[] calibration,
						String calibrationUnit,
						double[] translation )
	{

		final File hdf5File = new File( filePath + ".h5" );
		final File xmlFile = new File( filePath + ".xml" );

		// check the image type
		switch ( imp.getType() )
		{
			case ImagePlus.GRAY8:
			case ImagePlus.GRAY16:
			case ImagePlus.GRAY32:
				break;
			default:
				IJ.showMessage( "Only 8, 16, 32-bit images are supported currently!" );
				return;
		}

		// check the image dimensionality
		if ( imp.getNDimensions() < 3 )
		{
			IJ.showMessage( "Image must be at least 3-dimensional!" );
			return;
		}

		// get nanometerCalibration and image radius
		final double pw = calibration[ 0 ];
		final double ph = calibration[ 1 ];
		final double pd = calibration[ 2 ];
		String punit = calibrationUnit;
		if ( punit == null || punit.isEmpty() ) punit = "px";
		final FinalVoxelDimensions voxelSize =
				new FinalVoxelDimensions( punit, pw, ph, pd );
		final int w = imp.getWidth();
		final int h = imp.getHeight();
		final int d = imp.getNSlices();
		final FinalDimensions size = new FinalDimensions( new int[] { w, h, d } );

		// propose reasonable mipmap settings
		final ExportMipmapInfo autoMipmapSettings = ProposeMipmaps.proposeMipmaps( new BasicViewSetup( 0, "", size, voxelSize ) );

		final ProgressWriter progressWriter = new ProgressWriterBdv();
		progressWriter.out().println( "starting export..." );

		// create ImgLoader wrapping the image
		final ImagePlusImgLoader< ? > imgLoader = getImagePlusImgLoader( imp );

		final int numTimepoints = imp.getNFrames();
		final int numSetups = imp.getNChannels();

		// create SourceTransform from the images nanometerCalibration
		final AffineTransform3D sourceTransform = new AffineTransform3D();
		sourceTransform.set( pw, 0, 0, 0,
				0, ph, 0, 0, 0, 0, pd, 0 );
		sourceTransform.translate( translation );

		// write hdf5
		final HashMap< Integer, BasicViewSetup > setups = new HashMap<>( numSetups );
		for ( int s = 0; s < numSetups; ++s )
		{
			String name =  imp.getTitle();

			if ( numSetups > 1 )
			{
				name += String.format( " - channel %d", s + 1 );
			}

			final BasicViewSetup setup = new BasicViewSetup( s, name, size, voxelSize );
			setup.setAttribute( new Channel( s + 1 ) );
			setups.put( s, setup );
		}

		final ArrayList< TimePoint > timepoints = new ArrayList<>( numTimepoints );

		for ( int t = 0; t < numTimepoints; ++t )
			timepoints.add( new TimePoint( t ) );

		final SequenceDescriptionMinimal seq =
				new SequenceDescriptionMinimal(
						new TimePoints( timepoints ),
						setups, imgLoader, null );

		Map< Integer, ExportMipmapInfo > perSetupExportMipmapInfo;
		perSetupExportMipmapInfo = new HashMap<>();
		final ExportMipmapInfo mipmapInfo =
				new ExportMipmapInfo(
						autoMipmapSettings.getExportResolutions(),
						autoMipmapSettings.getSubdivisions() );

		for ( final BasicViewSetup setup : seq.getViewSetupsOrdered() )
			perSetupExportMipmapInfo.put( setup.getId(), mipmapInfo );

		// LoopBackHeuristic:
		// - If saving more than 8x on pixel reads use the loopback image over
		//   original image
		// - For virtual stacks also consider the cache radius that would be
		//   required for all original planes contributing to a "plane of
		//   blocks" at the current level. If this is more than 1/4 of
		//   available memory, use the loopback image.
		final boolean isVirtual = imp.getStack().isVirtual();
		final long planeSizeInBytes = imp.getWidth() * imp.getHeight() * imp.getBytesPerPixel();
		final long ijMaxMemory = IJ.maxMemory();
		final int numCellCreatorThreads = Math.max( 1, PluginHelper.numThreads() - 1 );
		final WriteSequenceToHdf5.LoopbackHeuristic loopbackHeuristic =
				( originalImg,
				  factorsToOriginalImg,
				  previousLevel,
				  factorsToPreviousLevel,
				  chunkSize ) ->
		{
			if ( previousLevel < 0 )
				return false;

			if ( WriteSequenceToHdf5.numElements( factorsToOriginalImg ) / WriteSequenceToHdf5.numElements( factorsToPreviousLevel ) >= 8 )
				return true;

			if ( isVirtual )
			{
				final long requiredCacheSize = planeSizeInBytes * factorsToOriginalImg[ 2 ] * chunkSize[ 2 ];
				if ( requiredCacheSize > ijMaxMemory / 4 )
					return true;
			}

			return false;
		};

		final WriteSequenceToHdf5.AfterEachPlane afterEachPlane = usedLoopBack ->
		{
			if ( !usedLoopBack && isVirtual )
			{
				final long free = Runtime.getRuntime().freeMemory();
				final long total = Runtime.getRuntime().totalMemory();
				final long max = Runtime.getRuntime().maxMemory();
				final long actuallyFree = max - total + free;

				if ( actuallyFree < max / 2 )
					imgLoader.clearCache();
			}
		};


		final ArrayList< Partition > partitions;
		partitions = null;
		WriteSequenceToHdf5.writeHdf5File( seq, perSetupExportMipmapInfo, true, hdf5File, loopbackHeuristic, afterEachPlane, numCellCreatorThreads, new SubTaskProgressWriter( progressWriter, 0, 0.95 ) );

		// write xml sequence description
		final Hdf5ImageLoader hdf5Loader = new Hdf5ImageLoader( hdf5File, partitions, null, false );
		final SequenceDescriptionMinimal seqh5 = new SequenceDescriptionMinimal( seq, hdf5Loader );

		final ArrayList< ViewRegistration > registrations = new ArrayList<>();
		for ( int t = 0; t < numTimepoints; ++t )
			for ( int s = 0; s < numSetups; ++s )
				registrations.add( new ViewRegistration( t, s, sourceTransform ) );

		final File basePath = xmlFile.getParentFile();
		final SpimDataMinimal spimData = new SpimDataMinimal( basePath, seqh5, new ViewRegistrations( registrations ) );

		try
		{
			new XmlIoSpimDataMinimal().save( spimData, xmlFile.getAbsolutePath() );
			progressWriter.setProgress( 1.0 );
		}
		catch ( final Exception e )
		{
			throw new RuntimeException( e );
		}
		progressWriter.out().println( "done" );
	}

	public static ImagePlusImgLoader< ? > getImagePlusImgLoader( ImagePlus imp )
	{
		final ImagePlusImgLoader< ? > imgLoader;
		switch ( imp.getType() )
		{
			case ImagePlus.GRAY8:
				imgLoader = ImagePlusImgLoader.createGray8( imp, ImagePlusImgLoader.MinMaxOption.SET, 0, 255 );
				break;
			case ImagePlus.GRAY16:
				imgLoader = ImagePlusImgLoader.createGray16( imp, ImagePlusImgLoader.MinMaxOption.SET, 0, 65535 );
				break;
			case ImagePlus.GRAY32:
			default:
				imgLoader = ImagePlusImgLoader.createGray32( imp, ImagePlusImgLoader.MinMaxOption.COMPUTE, 0, 1 );
				break;
		}
		return imgLoader;
	}
}
